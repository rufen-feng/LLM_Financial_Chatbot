{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64dab348",
   "metadata": {},
   "source": [
    "## Content \n",
    "   * Simple RNN's\n",
    "   * Word Embeddings : Definition and How to get them\n",
    "   * LSTM's\n",
    "   * GRU's\n",
    "   * BI-Directional RNN's\n",
    "   * Encoder-Decoder Models (Seq2Seq Models)\n",
    "   * Attention Models\n",
    "   * Transformers - Attention is all you need\n",
    "   * BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f25159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical  # np_utils functionality is now in to_categorical\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing import sequence, text\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90086867",
   "metadata": {},
   "source": [
    "### Setup TPU\n",
    "A Tensor Processing Unit (TPU) is a type of hardware accelerator designed by Google specifically for machine learning workloads, particularly for neural network training and inference. TPUs are part of Google's broader AI hardware strategy and are optimized to handle large-scale computations for deep learning tasks more efficiently than general-purpose processors like CPUs (Central Processing Units) or even GPUs (Graphics Processing Units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f29f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rufen/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Detect if TPU is available and initialize it\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # Detect TPU\n",
    "    print('Running on TPU:', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    # Connect to TPU\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)  # Create a TPU strategy\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy()  # For GPU or multi-GPU machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e4a07a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/rufen/Downloads/jigsaw-toxic-comment-train.csv')\n",
    "validation = pd.read_csv('/Users/rufen/Downloads/jigsaw_validation.csv')\n",
    "test = pd.read_csv('/Users/rufen/Downloads/jigsaw_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bedab37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4be72e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['severe_toxic','obscene','threat','insult','identity_hate'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98aa9862",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.loc[:12000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25e3692b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12001, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e89a9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1403"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment_text'].apply(lambda x:len(str(x).split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19d3feef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(predictions,target):\n",
    "    '''\n",
    "    This methods returns the AUC Score when given the Predictions\n",
    "    and Labels\n",
    "    '''\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dc96410",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train.comment_text.values, train.toxic.values, \n",
    "                                                  stratify=train.toxic.values, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcd86d5",
   "metadata": {},
   "source": [
    "### RNN's\n",
    "Recurrent Neural Networks (RNNs) are a type of neural network that is particularly well-suited for sequential data and time series analysis. They are designed to handle input data of variable length and to capture dependencies and patterns across sequences. Here are a few reasons why RNNs are preferred over simple feedforward neural networks for sequential data:\n",
    "\n",
    "Handling sequential data: RNNs are designed to handle sequential data where the order of inputs matters. They have a \"memory\" element that allows them to process each input in the context of previous inputs. This makes them suitable for tasks like speech recognition, language modeling, time series prediction, and machine translation.\n",
    "\n",
    "Variable input length: Unlike traditional feedforward neural networks, RNNs can process inputs of variable lengths. This flexibility is crucial for tasks where the length of the input sequences can vary, such as natural language processing tasks.\n",
    "\n",
    "Temporal dependencies: RNNs are capable of capturing temporal dependencies in sequential data. They can remember information from previous time steps and use it to make predictions at the current time step. This makes them well-suited for tasks that involve analyzing time series data or sequences with long-range dependencies.\n",
    "\n",
    "Parameter sharing: RNNs have shared weights across time steps, which allows them to efficiently learn patterns in sequential data. This parameter sharing helps in reducing the number of parameters to be learned compared to simple feedforward neural networks, making RNNs more effective for tasks with sequential data.\n",
    "\n",
    "Backpropagation through time: RNNs use a technique called backpropagation through time (BPTT) to update the model's weights. This technique allows the network to learn from sequences of data by unfolding the network in time and applying the standard backpropagation algorithm. This enables the network to learn complex patterns in sequential data.\n",
    "\n",
    "While RNNs are powerful for handling sequential data, they also have some limitations such as difficulty in learning long-term dependencies (vanishing or exploding gradient problem) and difficulty in capturing dependencies that are very far apart in the sequence. To address some of these limitations, more advanced architectures like Long Short-Term Memory (LSTM) networks and Gated Recurrent Units (GRUs) have been developed, which are extensions of the basic RNN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30cf28e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using keras tokenizer here\n",
    "token = text.Tokenizer(num_words=None)\n",
    "max_len = 1500\n",
    "\n",
    "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
    "xtrain_seq = token.texts_to_sequences(xtrain)\n",
    "xvalid_seq = token.texts_to_sequences(xvalid)\n",
    "\n",
    "#zero pad the sequences\n",
    "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0534655b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1500, 300)         13049100  \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 100)               40100     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13089301 (49.93 MB)\n",
      "Trainable params: 13089301 (49.93 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "CPU times: user 115 ms, sys: 93.8 ms, total: 209 ms\n",
      "Wall time: 333 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with strategy.scope():\n",
    "    # A simpleRNN without any pretrained embeddings and one dense layer\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     input_length=max_len))\n",
    "    model.add(SimpleRNN(100)) \n",
    "    # 100 refers to the number of units (also known as neurons or hidden states)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "   \n",
    "    # Binary cross-entropy measures the difference between the true labels and the predicted probabilities.\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3da5df97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 15:46:05.314724: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 88s 584ms/step - loss: 0.3098 - accuracy: 0.8979\n",
      "Epoch 2/5\n",
      "150/150 [==============================] - 88s 585ms/step - loss: 0.1295 - accuracy: 0.9541\n",
      "Epoch 3/5\n",
      "150/150 [==============================] - 88s 584ms/step - loss: 0.0237 - accuracy: 0.9929\n",
      "Epoch 4/5\n",
      "150/150 [==============================] - 87s 577ms/step - loss: 0.0047 - accuracy: 0.9991\n",
      "Epoch 5/5\n",
      "150/150 [==============================] - 89s 595ms/step - loss: 8.1798e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2d32f08e0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_pad, ytrain, epochs=5, batch_size=64*strategy.num_replicas_in_sync) #Multiplying by Strategy to run on TPU's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23855f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 15:54:51.011713: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 6s 82ms/step\n",
      "Auc: 0.83%\n"
     ]
    }
   ],
   "source": [
    "scores = model.predict(xvalid_pad)\n",
    "print(\"Auc: %.2f%%\" % (roc_auc(scores,yvalid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af3d2e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model = []\n",
    "scores_model.append({'Model': 'SimpleRNN','AUC_Score': roc_auc(scores,yvalid)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add53a91",
   "metadata": {},
   "source": [
    "### LSTM's\n",
    "\n",
    "Simple RNN's were certainly better than classical ML algorithms and gave state of the art results, but it failed to capture long term dependencies that is present in sentences . So in 1998-99 LSTM's were introduced to counter to these drawbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cd8196",
   "metadata": {},
   "source": [
    "### LSTM VS RNN\n",
    "\n",
    "循环神经网络(RNN)是一种针对序列数据处理的神经网络结构。它的主要特点是通过循环层实现数据的持久化，使得网络可以记忆之前的信息，从而对序列数据进行建模。RNN的一个重要变种是长短时记忆网络(LSTM)，它可以有效地解决传统 RNN中存在的梯度消失和梯度爆炸的问题。LSTM通过引入记忆单元和门控机制，使得网络可以选择性地记忆或遗忘之前的信息，从而更加有效地学习长序列数据的特征。\n",
    "\n",
    "* (1) RNN没有细胞状态而LSTM通过细胞状态记忆信息;\n",
    "* (2) RNN激活函数只有tanh 函数而 LSTM 通过输入门、遗忘门、输出门引入 sigmoid 函数并结合 tanh 函数，添加求和操作，减少梯度消失和梯度爆炸的可能性;\n",
    "* (3) RNN只能够处理短期依赖问题; LSTM 既能够处理短期依赖问题，又能够处理长期依赖问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74cdac67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196018it [01:10, 31186.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2196017 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load the GloVe vectors in a dictionary:\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('/Users/rufen/Downloads/glove.840B.300d.txt','r',encoding='utf-8')\n",
    "for line in tqdm(f):\n",
    "    values = line.split(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray([float(val) for val in values[1:]])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8425d012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 43496/43496 [00:07<00:00, 5848.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# create an embedding matrix for the words we have in the dataset\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5693ee83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 1500, 300)         13049100  \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               160400    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13209601 (50.39 MB)\n",
      "Trainable params: 160501 (626.96 KB)\n",
      "Non-trainable params: 13049100 (49.78 MB)\n",
      "_________________________________________________________________\n",
      "CPU times: user 133 ms, sys: 156 ms, total: 289 ms\n",
      "Wall time: 1.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with strategy.scope():\n",
    "    \n",
    "    # A simple LSTM with glove embeddings and one dense layer\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "\n",
    "    model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
    "    # dropout 是一种正则化技术，用于防止模型过拟合。\n",
    "    # 在训练过程中，以 0.3（即 30%）的概率随机地丢弃输入单元的某些值。这意味着在每次训练迭代中，有 30% 的输入单元会被忽略，有助于提高模型的泛化能力。\n",
    "    # recurrent_dropout 是针对 LSTM 单元内部递归状态的 dropout。\n",
    "    # 在 LSTM 层的时间步之间，以 0.3（即 30%）的概率丢弃 LSTM 单元的递归连接。这有助于防止模型在处理长时间序列时过拟合。\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90b6ddfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 16:43:04.368929: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 467s 3s/step - loss: 0.2064 - accuracy: 0.9272\n",
      "Epoch 2/5\n",
      "150/150 [==============================] - 456s 3s/step - loss: 0.1374 - accuracy: 0.9532\n",
      "Epoch 3/5\n",
      "150/150 [==============================] - 454s 3s/step - loss: 0.1240 - accuracy: 0.9558\n",
      "Epoch 4/5\n",
      "150/150 [==============================] - 570s 4s/step - loss: 0.1118 - accuracy: 0.9609\n",
      "Epoch 5/5\n",
      "150/150 [==============================] - 683s 5s/step - loss: 0.1062 - accuracy: 0.9624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x481955630>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_pad, ytrain, epochs=5, batch_size=64*strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41c04a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 17:28:39.623845: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 43s 561ms/step\n",
      "Auc: 0.97%\n"
     ]
    }
   ],
   "source": [
    "scores = model.predict(xvalid_pad)\n",
    "print(\"Auc: %.2f%%\" % (roc_auc(scores,yvalid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0884ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model.append({'Model': 'LSTM','AUC_Score': roc_auc(scores,yvalid)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69799c6",
   "metadata": {},
   "source": [
    "### GRU's\n",
    "\n",
    "Introduced by Cho, et al. in 2014, GRU (Gated Recurrent Unit) aims to solve the vanishing gradient problem which comes with a standard recurrent neural network. GRU's are a variation on the LSTM because both are designed similarly and, in some cases, produce equally excellent results . GRU's were designed to be simpler and faster than LSTM's and in most cases produce equally good results and thus there is no clear winner."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
